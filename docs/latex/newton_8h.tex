\hypertarget{newton_8h}{}\doxysection{optimizers/newton.h File Reference}
\label{newton_8h}\index{optimizers/newton.h@{optimizers/newton.h}}
{\ttfamily \#include \char`\"{}../core/options.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}../core/parameters.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}../core/constrained\+\_\+optimization.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}../core/transformation.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}../core/derivative.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}loss\+\_\+functions.\+h\char`\"{}}\newline
{\ttfamily \#include $<$limits$>$}\newline
{\ttfamily \#include $<$numeric$>$}\newline
{\ttfamily \#include $<$sstream$>$}\newline
{\ttfamily \#include $<$iomanip$>$}\newline
\doxysubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classco_1_1_newton_optimizer}{co\+::\+Newton\+Optimizer$<$ E $>$}}
\end{DoxyCompactItemize}
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
{\footnotesize template$<$class T $>$ }\\std\+::string \mbox{\hyperlink{newton_8h_a596b395f514503ae33efe338336983b4}{co\+::print\+\_\+info}} (const E\+Var\+Manager$<$ T $>$ \&vars, const std\+::vector$<$ T $>$ \&J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled, size\+\_\+t iteration, T squared\+\_\+error)
\item 
template$<$$>$ std\+::string \mbox{\hyperlink{newton_8h_a60c0d2162034e2fc845730aedb9c2b55}{co\+::print\+\_\+info$<$ E\+Float64 $>$}} (const E\+Var\+Manager$<$ E\+Float64 $>$ \&vars, const std\+::vector$<$ E\+Float64 $>$ \&J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled, size\+\_\+t iteration, E\+Float64 squared\+\_\+error)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
The Gauss Newton procedure minimizes functions that can be represented as sums of squares. While the implementation is generic and straightforward, instances of \mbox{\hyperlink{evaluation_8h}{evaluation.\+h}} heavily steer the way the actual compuation is done. Currently three line search methods are implemented. 

\doxysubsection{Function Documentation}
\mbox{\Hypertarget{newton_8h_a596b395f514503ae33efe338336983b4}\label{newton_8h_a596b395f514503ae33efe338336983b4}} 
\index{newton.h@{newton.h}!print\_info@{print\_info}}
\index{print\_info@{print\_info}!newton.h@{newton.h}}
\doxysubsubsection{\texorpdfstring{print\_info()}{print\_info()}}
{\footnotesize\ttfamily template$<$class T $>$ \\
std\+::string co\+::print\+\_\+info (\begin{DoxyParamCaption}\item[{const E\+Var\+Manager$<$ T $>$ \&}]{vars,  }\item[{const std\+::vector$<$ T $>$ \&}]{J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled,  }\item[{size\+\_\+t}]{iteration,  }\item[{T}]{squared\+\_\+error }\end{DoxyParamCaption})}

Creates a string that stores information about the current Newton iteration. This information includes the values of the currently estimated parameters, error measures and covariances. Because the number of digits saved in the string heavily depends on the width of the underlying numeric datatype, the function is templatized. This entails that wider types save more digits while shorter types are stored with less precision. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em vars} & The status of the variables of the current Newton iteration. \\
\hline
\mbox{\texttt{ in}}  & {\em J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled} & Inverse of first order Hessian approximation multiplied by the standard deviation. Serves as approximation to Covariance Matrix. \\
\hline
\mbox{\texttt{ in}}  & {\em iteration} & Current Newton iteration \\
\hline
\mbox{\texttt{ in}}  & {\em squared\+\_\+error} & Estimated of squared error between the experimental data points and the simulated data points. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
String containing formatted information about the current optimization iteration 
\end{DoxyReturn}
\mbox{\Hypertarget{newton_8h_a60c0d2162034e2fc845730aedb9c2b55}\label{newton_8h_a60c0d2162034e2fc845730aedb9c2b55}} 
\index{newton.h@{newton.h}!print\_info$<$ EFloat64 $>$@{print\_info$<$ EFloat64 $>$}}
\index{print\_info$<$ EFloat64 $>$@{print\_info$<$ EFloat64 $>$}!newton.h@{newton.h}}
\doxysubsubsection{\texorpdfstring{print\_info$<$ EFloat64 $>$()}{print\_info< EFloat64 >()}}
{\footnotesize\ttfamily template$<$$>$ \\
std\+::string co\+::print\+\_\+info$<$ E\+Float64 $>$ (\begin{DoxyParamCaption}\item[{const E\+Var\+Manager$<$ E\+Float64 $>$ \&}]{vars,  }\item[{const std\+::vector$<$ E\+Float64 $>$ \&}]{J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled,  }\item[{size\+\_\+t}]{iteration,  }\item[{E\+Float64}]{squared\+\_\+error }\end{DoxyParamCaption})}

Creates a string that stores information about the current Newton iteration for the E\+Float64 datatype. This information includes the values of the currently estimated parameters, error measures and covariances. Because E\+Float64\textquotesingle{}s underlying value type is a double, 15 digits of precision are saved. Please note that this does not mean that all 15 digits are reliable. Look at the low and high error bounds of the datatype to get an estimate of its true value. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\texttt{ in}}  & {\em vars} & The status of the variables of the current Newton iteration. \\
\hline
\mbox{\texttt{ in}}  & {\em J\+\_\+\+T\+\_\+\+J\+\_\+inv\+\_\+scaled} & Inverse of first order Hessian approximation multiplied by the standard deviation. Serves as approximation to Covariance Matrix. \\
\hline
\mbox{\texttt{ in}}  & {\em iteration} & Current Newton iteration \\
\hline
\mbox{\texttt{ in}}  & {\em squared\+\_\+error} & Estimated of squared error between the experimental data points and the simulated data points \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
String containing formatted information about the current optimization iteration 
\end{DoxyReturn}
